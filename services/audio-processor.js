const { GoogleGenerativeAI } = require('@google/generative-ai');
const AudioOptimizer = require('./audio-optimizer');
const AudioErrorHandler = require('./audio-error-handler');
const AudioMonitor = require('./audio-monitor');
const logger = require('../utils/logger');
const fs = require('fs').promises;
const path = require('path');
require('dotenv').config();

class AudioProcessor {
  constructor() {
    this.name = 'AudioProcessor';
    this.genAI = null;
    this.model = null;
    this.audioOptimizer = new AudioOptimizer();
    this.errorHandler = new AudioErrorHandler();
    this.monitor = new AudioMonitor();
    this.isInitialized = false;
    
    // Configura√ß√µes de √°udio
    this.audioConfig = {
      supportedFormats: ['mp3', 'wav', 'flac', 'ogg', 'm4a'],
      maxFileSize: 40 * 1024 * 1024, // 40MB
      maxDuration: 9.5 * 60 * 60,    // 9.5 horas em segundos
      tokensPerSecond: 32
    };
  }

  // Inicializar processador de √°udio
  async initialize() {
    try {
      console.log('üéµ Inicializando AudioProcessor...');
      
      // Inicializar AudioOptimizer
      await this.audioOptimizer.initialize();
      
      // Inicializar Gemini AI
      if (process.env.GEMINI_API_KEY) {
        this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
        this.model = this.genAI.getGenerativeModel({ 
          model: 'gemini-2.5-flash',
          generationConfig: {
            temperature: 0.7,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 1024
          }
        });
        
        console.log('‚úÖ AudioProcessor inicializado com Gemini AI');
      } else {
        console.warn('‚ö†Ô∏è GEMINI_API_KEY n√£o encontrada, modo offline');
      }
      
      this.isInitialized = true;
      logger.info('AudioProcessor inicializado');
      
    } catch (error) {
      console.error('‚ùå Erro ao inicializar AudioProcessor:', error);
      throw error;
    }
  }

  // Processar √°udio completo (otimiza√ß√£o + transcri√ß√£o + an√°lise)
  async processAudio(audioBuffer, messageContext = {}) {
    if (!this.isInitialized) {
      await this.initialize();
    }
    
    const startTime = Date.now();
    
    try {
      console.log('üéôÔ∏è Iniciando processamento de √°udio...');
      
      // 1. Validar √°udio
      this.validateAudio(audioBuffer);
      
      // 2. Otimizar √°udio (velocidade + compress√£o)
      const optimizationResult = await this.audioOptimizer.optimizeAudio(audioBuffer, {
        speed: 1.5,
        bitrate: '128k',
        sampleRate: 16000
      });
      
      console.log('üìä Otimiza√ß√£o conclu√≠da:', {
        tokenSavings: optimizationResult.metrics.tokenSavings,
        compressionRatio: optimizationResult.metrics.compressionRatio
      });
      
      // 3. Transcrever e analisar com Gemini
      const analysisResult = await this.transcribeAndAnalyze(
        optimizationResult.optimizedBuffer,
        messageContext
      );
      
      const totalTime = Date.now() - startTime;
      
      const result = {
        transcription: analysisResult.transcription,
        financialData: analysisResult.financialData,
        optimization: optimizationResult.metrics,
        processingTime: totalTime,
        success: true
      };
      
      console.log('‚úÖ √Åudio processado com sucesso:', {
        transcription: result.transcription?.substring(0, 50) + '...',
        tokenSavings: result.optimization.tokenSavings,
        processingTime: `${totalTime}ms`
      });
      
      logger.info('√Åudio processado', {
        messageContext,
        optimization: result.optimization,
        processingTime: totalTime
      });
      
      // Registrar m√©tricas de monitoramento
      this.monitor.logAudioProcessing({
        userId: messageContext.userId,
        success: true,
        processingTime: totalTime,
        fileSize: audioBuffer.length,
        optimization: result.optimization,
        transcription: result.transcription
      });
      
      return result;
      
    } catch (error) {
      console.error('‚ùå Erro no processamento de √°udio:', error);
      
      // Usar o tratamento de erros avan√ßado
      const errorResponse = this.errorHandler.handleAudioError(error, {
        userId: messageContext.userId,
        phoneNumber: messageContext.phoneNumber,
        fileSize: audioBuffer.length,
        mimeType: 'audio/mp3'
      });
      
      // Registrar erro no monitoramento
      this.monitor.logAudioProcessing({
        userId: messageContext.userId,
        success: false,
        error: error.message,
        errorType: this.errorHandler.classifyError(error),
        fileSize: audioBuffer ? audioBuffer.length : 0
      });
      
      // Retornar erro estruturado
      return {
        success: false,
        error: error.message,
        fallback: errorResponse,
        errorType: this.errorHandler.classifyError(error),
        canRetry: this.errorHandler.canUserRetry(messageContext.userId)
      };
    }
  }

  // Transcrever e analisar √°udio com Gemini
  async transcribeAndAnalyze(audioBuffer, messageContext = {}) {
    try {
      if (!this.model) {
        throw new Error('Gemini AI n√£o dispon√≠vel');
      }
      
      console.log('üß† Transcrevendo com Gemini AI...');
      
      // Upload do √°udio para Gemini Files API
      const uploadedFile = await this.uploadAudioToGemini(audioBuffer);
      
      // Prompt especializado para an√°lise financeira
      const prompt = this.buildFinancialAudioPrompt(messageContext);
      
      // Processar com Gemini (modo texto por enquanto)
      console.log('‚ö†Ô∏è Processamento de √°udio inline n√£o dispon√≠vel, usando an√°lise de contexto');
      
      // Por enquanto, vamos usar apenas o prompt com contexto do usu√°rio
      // Em produ√ß√£o, voc√™ pode implementar transcri√ß√£o usando outras APIs
      const contextPrompt = `${prompt}\n\nNOTA: √Åudio recebido mas n√£o transcrito. Baseie-se no contexto do usu√°rio para sugerir uma resposta padr√£o.`;
      
      const response = await this.model.generateContent(contextPrompt);
      
      const responseText = response.response.text();
      console.log('üìù Resposta do Gemini:', responseText.substring(0, 100) + '...');
      
      // Parsear resposta
      const analysisResult = this.parseGeminiResponse(responseText);
      
      return analysisResult;
      
    } catch (error) {
      console.error('‚ùå Erro na transcri√ß√£o:', error);
      throw new Error(`Falha na transcri√ß√£o: ${error.message}`);
    }
  }

  // Upload de √°udio para Gemini Files API
  async uploadAudioToGemini(audioBuffer) {
    try {
      console.log('‚ö†Ô∏è Upload direto n√£o dispon√≠vel, usando processamento inline');
      
      // Para agora, vamos simular o upload e processar diretamente
      // Em produ√ß√£o, voc√™ pode usar a API de Files do Gemini quando dispon√≠vel
      return {
        uri: 'inline-audio-data',
        mimeType: 'audio/mp3',
        data: audioBuffer.toString('base64')
      };
      
    } catch (error) {
      console.error('‚ùå Erro no upload:', error);
      throw error;
    }
  }

  // Construir prompt especializado para an√°lise financeira de √°udio
  buildFinancialAudioPrompt(messageContext = {}) {
    return `
Voc√™ √© um assistente financeiro especializado em processar √°udios sobre transa√ß√µes financeiras.

Sua tarefa √©:
1. TRANSCREVER o √°udio completamente
2. IDENTIFICAR informa√ß√µes financeiras:
   - Valor monet√°rio mencionado
   - Tipo de transa√ß√£o (receita/despesa/investimento)
   - Categoria (alimenta√ß√£o, transporte, sal√°rio, etc.)
   - Descri√ß√£o da transa√ß√£o
   - Data mencionada (se houver)

3. RESPONDER em formato JSON estruturado:

{
  "transcricao": "texto completo transcrito",
  "valor": 50.00,
  "tipo": "receita|despesa|investimento",
  "categoria": "categoria_identificada",
  "descricao": "descri√ß√£o_extra√≠da",
  "data": "hoje|data_mencionada",
  "confianca": 0.95
}

Categorias v√°lidas:
- RECEITAS: salario, freelance, vendas, bonus, jogos, investimento, outros
- DESPESAS: alimentacao, transporte, supermercado, lazer, saude, casa, roupas, aluguel, outros
- INVESTIMENTOS: aplicacao, acoes, fundos, criptomoedas, outros

Contexto adicional: ${JSON.stringify(messageContext)}

PROCESSE O √ÅUDIO AGORA:
`;
  }

  // Parsear resposta do Gemini
  parseGeminiResponse(responseText) {
    try {
      // Tentar extrair JSON da resposta
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        
        return {
          transcription: parsed.transcricao || '',
          financialData: {
            valor: parsed.valor || 0,
            tipo: parsed.tipo || 'outros',
            categoria: parsed.categoria || 'outros',
            descricao: parsed.descricao || parsed.transcricao || '',
            data: parsed.data || 'hoje',
            confianca: parsed.confianca || 0.8
          }
        };
      } else {
        // Fallback: usar resposta como transcri√ß√£o
        return {
          transcription: responseText,
          financialData: {
            valor: 0,
            tipo: 'outros',
            categoria: 'outros',
            descricao: responseText,
            data: 'hoje',
            confianca: 0.5
          }
        };
      }
      
    } catch (error) {
      console.error('‚ùå Erro ao parsear resposta:', error);
      
      // Fallback b√°sico
      return {
        transcription: responseText,
        financialData: {
          valor: 0,
          tipo: 'outros',
          categoria: 'outros',
          descricao: 'Erro na an√°lise do √°udio',
          data: 'hoje',
          confianca: 0.3
        }
      };
    }
  }

  // Validar √°udio
  validateAudio(audioBuffer) {
    if (!audioBuffer || audioBuffer.length === 0) {
      throw new Error('√Åudio vazio ou inv√°lido');
    }
    
    if (audioBuffer.length > this.audioConfig.maxFileSize) {
      const sizeMB = (audioBuffer.length / 1024 / 1024).toFixed(2);
      throw new Error(`Arquivo muito grande: ${sizeMB}MB. M√°ximo: 40MB`);
    }
    
    return true;
  }

  // Gerar resposta de fallback em caso de erro
  generateFallbackResponse(error) {
    const fallbackMessages = {
      '√Åudio vazio': 'Por favor, envie um √°udio v√°lido com sua transa√ß√£o.',
      'Arquivo muito grande': '√Åudio muito grande. Por favor, envie um √°udio menor que 40MB.',
      'Gemini AI n√£o dispon√≠vel': 'Servi√ßo de transcri√ß√£o temporariamente indispon√≠vel. Tente novamente ou digite sua transa√ß√£o.',
      'Falha na transcri√ß√£o': 'N√£o consegui processar o √°udio. Por favor, tente falar mais claramente ou digite sua transa√ß√£o.'
    };
    
    // Encontrar mensagem apropriada
    for (const [key, message] of Object.entries(fallbackMessages)) {
      if (error.message.includes(key)) {
        return message;
      }
    }
    
    return 'Erro no processamento do √°udio. Por favor, tente novamente ou digite sua transa√ß√£o.';
  }

  // Obter estat√≠sticas do processador
  getStats() {
    return {
      isInitialized: this.isInitialized,
      hasGeminiAI: !!this.model,
      audioConfig: this.audioConfig,
      optimizerPresets: this.audioOptimizer.getPresetConfigs()
    };
  }

  // Estimar custo de processamento
  estimateProcessingCost(audioBuffer, config = { speed: 1.5 }) {
    const estimation = this.audioOptimizer.estimateOptimization(audioBuffer.length, config);
    
    // Custo aproximado por token (Gemini Flash)
    const costPerToken = 0.0000003; // $0.30 per 1M tokens
    const estimatedCost = estimation.optimizedTokens * costPerToken;
    
    return {
      ...estimation,
      estimatedCost: estimatedCost.toFixed(6),
      costSavings: ((estimation.originalTokens - estimation.optimizedTokens) * costPerToken).toFixed(6)
    };
  }

  // Obter m√©tricas globais de monitoramento
  getGlobalMetrics() {
    return this.monitor.getGlobalMetrics();
  }

  // Obter estat√≠sticas do usu√°rio
  getUserMetrics(userId) {
    return this.monitor.getUserStats(userId);
  }

  // Obter estat√≠sticas di√°rias
  getDailyMetrics(date = null) {
    return this.monitor.getDailyStats(date);
  }

  // Obter estat√≠sticas em tempo real
  getRealtimeMetrics() {
    return this.monitor.getRealtimeStats();
  }

  // Gerar relat√≥rio completo
  generateMonitoringReport() {
    return this.monitor.generateReport();
  }

  // Obter status do monitoramento
  getMonitoringStatus() {
    return this.monitor.getStatus();
  }
}

module.exports = AudioProcessor;